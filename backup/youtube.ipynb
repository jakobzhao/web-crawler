{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# created on April 14, 2021\n",
        "# modified on Jan 2, 2022\n",
        "# modified on April 2o, 2023\n",
        "# @author:          Bo Zhao\n",
        "# @email:           zhaobo@uw.edu\n",
        "# @website:         https://hgis.uw.edu\n",
        "# @organization:    Department of Geography, University of Washington, Seattle\n",
        "# @description:     A demo of collecting data from YouTube."
      ],
      "metadata": {
        "id": "bVJiWG0ZQ35Z"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "1VMonPRy4f6J",
        "outputId": "3d014477-61c0-4933-fc94-b0c20406b2cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Executing: /tmp/apt-key-gpghome.oCanYsxIMe/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
            "gpg: key DCC9EFBF77E11517: \"Debian Stable Release Key (10/buster) <debian-release@lists.debian.org>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Executing: /tmp/apt-key-gpghome.dti8r3SdwD/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
            "gpg: key DC30D7C23CBBABEE: \"Debian Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "Executing: /tmp/apt-key-gpghome.wedPhzQ8Ly/gpg.1.sh --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
            "gpg: key 4DFAB270CAA96DFA: \"Debian Security Archive Automatic Signing Key (10/buster) <ftpmaster@debian.org>\" not changed\n",
            "gpg: Total number processed: 1\n",
            "gpg:              unchanged: 1\n",
            "gpg: cannot open '/dev/tty': No such device or address\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "gpg: [stdout]: write error: Broken pipe\n",
            "gpg: filter_flush failed on close: Broken pipe\n",
            "gpg: cannot open '/dev/tty': No such device or address\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "gpg: [stdout]: write error: Broken pipe\n",
            "gpg: filter_flush failed on close: Broken pipe\n",
            "gpg: cannot open '/dev/tty': No such device or address\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "gpg: [stdout]: write error: Broken pipe\n",
            "gpg: filter_flush failed on close: Broken pipe\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "%%shell\n",
        "# Ubuntu no longer distributes chromium-browser outside of snap\n",
        "#\n",
        "# Proposed solution: https://askubuntu.com/questions/1204571/how-to-install-chromium-without-snap\n",
        "\n",
        "# Add debian buster\n",
        "cat > /etc/apt/sources.list.d/debian.list <<'EOF'\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster.gpg] http://deb.debian.org/debian buster main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-buster-updates.gpg] http://deb.debian.org/debian buster-updates main\n",
        "deb [arch=amd64 signed-by=/usr/share/keyrings/debian-security-buster.gpg] http://deb.debian.org/debian-security buster/updates main\n",
        "EOF\n",
        "\n",
        "# Add keys\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys DCC9EFBF77E11517\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 648ACFD622F3D138\n",
        "apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 112695A0E562B32A\n",
        "\n",
        "apt-key export 77E11517 | gpg --dearmour -o /usr/share/keyrings/debian-buster.gpg\n",
        "apt-key export 22F3D138 | gpg --dearmour -o /usr/share/keyrings/debian-buster-updates.gpg\n",
        "apt-key export E562B32A | gpg --dearmour -o /usr/share/keyrings/debian-security-buster.gpg\n",
        "\n",
        "# Prefer debian repo for chromium* packages only\n",
        "# Note the double-blank lines between entries\n",
        "cat > /etc/apt/preferences.d/chromium.pref << 'EOF'\n",
        "Package: *\n",
        "Pin: release a=eoan\n",
        "Pin-Priority: 500\n",
        "\n",
        "\n",
        "Package: *\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 300\n",
        "\n",
        "\n",
        "Package: chromium*\n",
        "Pin: origin \"deb.debian.org\"\n",
        "Pin-Priority: 700\n",
        "EOF\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install chromium chromium-driver\n",
        "!pip3 install selenium\n",
        "!pip install kora -q"
      ],
      "metadata": {
        "id": "zMY83ivH4_Tc",
        "outputId": "0f80b069-780b-45ca-bafe-a05ba6d1d987",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://deb.debian.org/debian buster InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connecting to clo\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r                                                                               \rHit:3 http://deb.debian.org/debian buster-updates InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connecting to clo\r                                                                               \rHit:4 http://deb.debian.org/debian-security buster/updates InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connecting to clo\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "\r0% [Waiting for headers] [Connecting to security.ubuntu.com] [Connecting to clo\r                                                                               \rHit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "\r0% [Connecting to security.ubuntu.com (91.189.91.81)] [Connected to cloud.r-pro\r                                                                               \rHit:7 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "\r0% [Connected to cloud.r-project.org (108.157.173.54)] [Connected to r2u.stat.i\r                                                                               \rHit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:9 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "chromium is already the newest version (90.0.4430.212-1~deb10u1).\n",
            "chromium-driver is already the newest version (90.0.4430.212-1~deb10u1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (2.4.0)\n",
            "Requirement already satisfied: trio~=0.17 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.1.31)\n",
            "Requirement already satisfied: typing_extensions~=4.9 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.13.2)\n",
            "Requirement already satisfied: websocket-client~=1.8 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.17->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the Old Chrome and ChromeDriver\n",
        "\n",
        "!apt-get purge chromium-browser chromium-chromedriver"
      ],
      "metadata": {
        "id": "JYAvgZPienG-",
        "outputId": "f769d7a2-5c70-4333-8ff2-27e5b8cce16c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Package 'chromium-browser' is not installed, so not removed\n",
            "Package 'chromium-chromedriver' is not installed, so not removed\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install a Matching Version of Chrome and ChromeDriver\n",
        "\n",
        "# Download Chrome v90\n",
        "!wget https://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_90.0.4430.212-1_amd64.deb\n",
        "!dpkg -i google-chrome-stable_90.0.4430.212-1_amd64.deb\n",
        "\n",
        "# Install ChromeDriver for Chrome v90\n",
        "!wget https://chromedriver.storage.googleapis.com/90.0.4430.24/chromedriver_linux64.zip\n",
        "!unzip chromedriver_linux64.zip -d /usr/bin/"
      ],
      "metadata": {
        "id": "_GtYoXbUe9Ha",
        "outputId": "24aa5a3a-648e-4b6d-ce07-29fc5287c6b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-28 22:20:24--  https://dl.google.com/linux/chrome/deb/pool/main/g/google-chrome-stable/google-chrome-stable_90.0.4430.212-1_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 74.125.26.136, 74.125.26.93, 74.125.26.190, ...\n",
            "Connecting to dl.google.com (dl.google.com)|74.125.26.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-04-28 22:20:24 ERROR 404: Not Found.\n",
            "\n",
            "\u001b[1mdpkg:\u001b[0m \u001b[1;31merror:\u001b[0m cannot access archive 'google-chrome-stable_90.0.4430.212-1_amd64.deb': No such file or directory\n",
            "--2025-04-28 22:20:24--  https://chromedriver.storage.googleapis.com/90.0.4430.24/chromedriver_linux64.zip\n",
            "Resolving chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)... 142.250.98.207, 142.251.107.207, 74.125.196.207, ...\n",
            "Connecting to chromedriver.storage.googleapis.com (chromedriver.storage.googleapis.com)|142.250.98.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5795569 (5.5M) [application/zip]\n",
            "Saving to: ‘chromedriver_linux64.zip.1’\n",
            "\n",
            "chromedriver_linux6 100%[===================>]   5.53M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-04-28 22:20:25 (136 MB/s) - ‘chromedriver_linux64.zip.1’ saved [5795569/5795569]\n",
            "\n",
            "Archive:  chromedriver_linux64.zip\n",
            "replace /usr/bin/chromedriver? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: /usr/bin/chromedriver   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update Your Environment PATH\n",
        "\n",
        "import os\n",
        "os.environ[\"PATH\"] += \":/usr/bin/\""
      ],
      "metadata": {
        "id": "JvF2SyoRfOJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import time, datetime\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "#from kora.selenium import wd as bot\n",
        "\n",
        "options = Options()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "bot = webdriver.Chrome(\"chromedriver\", options=options)"
      ],
      "metadata": {
        "id": "KOJwgbYBRed3",
        "outputId": "257e6a43-31a4-42c5-d379-612ac216febc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "WebDriver.__init__() got multiple values for argument 'options'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d3857ff9945f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--headless\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--no-sandbox\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mbot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"chromedriver\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: WebDriver.__init__() got multiple values for argument 'options'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The url where the data will be collected from.\n",
        "url = \"https://www.youtube.com/results?search_query=standing+rock\"\n",
        "\n",
        "# Input the targeting url to the bot, and the bot will load data from the url.\n",
        "bot.get(url)\n",
        "\n",
        "# An array to store all the video urls. If a video has been crawled, it would not be stored to the data frame.\n",
        "video_urls = []\n",
        "# An array to store the retrieved video details.\n",
        "results = []\n",
        "\n",
        "\n",
        "# variable i indicates the number of times that scrolls down a web page. In practice, you might want to develop different\n",
        "# interaction approach to load and view the web pages.\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "    # Create a document object model (DOM) from the raw source of the crawled web page.\n",
        "    # Since you are processing a html page, 'html.parser' is chosen.\n",
        "    soup = BeautifulSoup(bot.page_source, 'html.parser')\n",
        "\n",
        "    # Capture all the video items using find_all or findAll method.\n",
        "    # To view the information of the html elements you want to collect, you need to inspect the raw source using Chrome Inspector.\n",
        "    # To test whether you find the right html elements, you can use the pycharm debugger to examine the returned data.\n",
        "    videos = soup.find_all('ytd-video-renderer', class_=\"style-scope ytd-item-section-renderer\")[-20:] # 20 indicates only process the newly-acquired 20 entries.\n",
        "\n",
        "    # iterate and process each video entry.\n",
        "    for video in videos:\n",
        "\n",
        "        # I prefer use the \"try-except\" statement to enable the program run without pausing due to unexpected errors.\n",
        "        try:\n",
        "            # video_url = video.find(\"a\", class_=\"yt-simple-endpoint inline-block style-scope ytd-thumbnail\").attrs[\"href\"]\n",
        "            # user_url = video.find(\"a\", class_=\"yt-simple-endpoint style-scope yt-formatted-string\").attrs[\"href\"]\n",
        "            # username = video.find(\"a\", class_=\"yt-simple-endpoint style-scope yt-formatted-string\").text\n",
        "            # title = video.find(\"yt-formatted-string\", class_=\"style-scope ytd-video-renderer\").text\n",
        "            # view_num = video.find_all(\"span\", class_=\"style-scope ytd-video-meta-block\")[0].text.replace(\" views\", \"\")\n",
        "            # created_at = video.find_all(\"span\", class_=\"style-scope ytd-video-meta-block\")[0].text.replace(\" ago\", \"\")\n",
        "            # shortdesc = video.find(\"yt-formatted-string\", id=\"description-text\").text\n",
        "            # collected_at = datetime.datetime.now()\n",
        "\n",
        "            video_url = video.find(\"a\", class_=\"yt-simple-endpoint style-scope ytd-video-renderer\").attrs[\"href\"]\n",
        "            user_url = video.find(\"a\", class_=\"yt-simple-endpoint style-scope yt-formatted-string\").attrs[\"href\"]\n",
        "            username = video.find(\"a\", class_=\"yt-simple-endpoint style-scope yt-formatted-string\").text\n",
        "            title = video.find(\"yt-formatted-string\", class_=\"style-scope ytd-video-renderer\").text\n",
        "            metadata_items = video.find_all(\"span\", class_=\"inline-metadata-item style-scope ytd-video-meta-block\")\n",
        "            view_num = metadata_items[0].text.replace(\" views\", \"\")\n",
        "            created_at = metadata_items[1].text.replace(\" ago\", \"\")\n",
        "            shortdesc = video.find(\"yt-formatted-string\", class_=\"metadata-snippet-text style-scope ytd-video-renderer\").text\n",
        "            collected_at = datetime.datetime.now()\n",
        "\n",
        "            # create a row in the dict format.\n",
        "            row = {'video_url': video_url,\n",
        "                    'user_url': user_url,\n",
        "                    'username': username,\n",
        "                    'title': title,\n",
        "                    'view_num': view_num,\n",
        "                    'created_at': created_at,\n",
        "                    'shortdesc': shortdesc,\n",
        "                    'collected_at': collected_at}\n",
        "\n",
        "            # if a video has been added, this video would not be inserted to the results array,\n",
        "            # otherwise, this video will be inserted.\n",
        "            if video_url in video_urls:\n",
        "                print(\"this video has already been added.\")\n",
        "            else:\n",
        "                print(row)\n",
        "                video_urls.append(video_url)\n",
        "                results.append(row)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # it is very important to enable the bot take some rest, and then resume to work.\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Let the bot scrolls down to the bottom of the content element, most of the time the bot needs to scroll down to the bottom of the page.\n",
        "    # like this statement: bot.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "    bot.execute_script('window.scrollTo(0,  document.getElementById(\"content\").scrollHeight);')\n",
        "\n",
        "# terminate the bot object.\n",
        "bot.close()\n",
        "\n",
        "# Store the results as a pandas dataframe\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "# notify the completion of the crawling in the console.\n",
        "print(\"the crawling task is finished.\")"
      ],
      "metadata": {
        "id": "uj2ClnTbRGp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data on to Google Drive\n",
        "from google.colab import drive\n",
        "# Mount your Drive to the Colab VM.\n",
        "#drive._mount('/gdrive')\n",
        "drive.mount('/gdrive')\n",
        "\n",
        "# the file path where to store the output csv on google drive\n",
        "output_file = '/gdrive/My Drive/videos.csv'\n",
        "\n",
        "# Save the dataframe as a csv file\n",
        "df.to_csv(output_file, index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3I9cWYBRI8r",
        "outputId": "e3dc7d97-03c2-4060-c8c3-e8726c39cb39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the csv to your local computer\n",
        "from google.colab import files\n",
        "files.download(output_file)\n",
        "print(\"the csv has been downloaded to your local computer. The program has been completed successfully.\")"
      ],
      "metadata": {
        "id": "ymNL_9hpTJwr",
        "outputId": "74eae079-a644-4442-f4e9-fd590d87a823",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c44deb31-fb3f-4522-aaf8-3667c1850759\", \"videos.csv\", 18888)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the csv has been downloaded to your local computer. The program has been completed successfully.\n"
          ]
        }
      ]
    }
  ]
}